Papers:
When Saliency Meets Sentiment: Understanding How Image Content Invokes Emotion and Sentiment

1. Very very good result, code available on github
   Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields

2. Deep Feature Flow for Video Recognition
  code: https://github.com/msracver/Deep-Feature-Flow
  Fast object detection and segmentation in a video. 
  22.25fps reported on the Cityscapes andImageNet VID dataset with NVIDIA K40 GPU and Intel Core i7-4790 CPU.
  The naive per-frame method runs 4.05 fps.
  Comparsion between the naive method, which can be seen as any state of the art segmentation and detection algorithom perform on every frame,
  and the proposed method, is as follwing:
                per-frame    proposed    dataset
  detection       73.9        73.1       ImageNet VID
  segmetation     71.1        69.2       Cityscapes
  I think the small loss of accuracy can be ingored.
  When I test the code, the result is not good at all.

3. One-Shot Video Object Segmentation
   code: http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/

4. Zero-Shot Learning - The Good, the Bad and the Ugly
  Many zero-shot got very very bad result in the wild, only good at the dataset the authors used.
  The author tried almost all zero shot methods and released code at  https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/zero-shot-learning/zero-shot-learning-the-good-the-bad-and-the-ugly/

5. Deep Image Matting
   Code(implenmented a baidu engineer): https://github.com/Joker316701882/Deep-Image-Matting
   The code is easy to run: having tensorflow prepared, download the pretrained model, then run it.
   His comment here: http://blog.leanote.com/post/calebge/Deep-Image-Matting%E5%A4%8D%E7%8E%B0%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93

5. Focal Loss for Dense Object Detection
   Unoffical code: https://github.com/unsky/focal-loss
   
6. Understanding Black-box Predictions via Influence Functions
   Someone's comment: https://github.com/eolecvk/InfluenceFunctions/blob/master/review.pdf
   Another comment: http://nooverfit.com/wp/icml-2017%E8%AE%BA%E6%96%87%E7%B2%BE%E9%80%891-%E7%94%A8%E5%BD%B1%E5%93%8D%E5%87%BD%E6%95%B0%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E9%BB%91%E7%9B%92%E9%A2%84/
7. Convexified Convolutional Neural Networks
   official code: https://github.com/zhangyuc/CCNN

8. On Calibration of Modern Neural Networks
   [来自知乎] 也是在deep learning session, 也是百分之百的实验。不过它报告了一个俺从来没有注意过的有趣现象：
   基于深度网络的分类器输出的class label probability 都over-confident；而这种现象在浅层网络中并不存在。这后面没准有东西可以挖一挖。

9. Learned Invariant Feature Transform
   Use CNN to generate key point descriptors.
   Code: https://github.com/cvlab-epfl/LIFT

10. Person Re-identification in the Wild

11. NetVLAD: CNN architecture for weakly supervised place recognition

12. These are learning with nosiy labels:
    Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach CVPR 2017
          See my comment.
          
    Toward robustness against label noise in training deep discriminative neural networks ICLR 2017
          In this paper, their model are not suitable for unknown T in "Making Deep Neural Networks Robust to Label Noise: a Loss 
          Correction Approach". Known T is used.
          
    Learning from noisy large-scale datasets with minimal supervision CVPR 2017
          i.  Their algorithm can be explained with one picture(fig 3). But you probably need to read section 3 to understand figure 3.
          ii. From table 2(their result), I think their result is not good, since they got only 2(on AP), and 1(on MAP) point precision 
              increasement, compared to "Fine-Tuning with clean labels", which is a very simple and naive method. They have a very very 
              complex network compared to simple "Fine-Tuning with clean labels". 
              I think, compared to "Fine-Tuning with clean labels", of course, the model can get better performance, since it utilizes 
              prior knowledge. But the result is not much better than simple, naive method.
          iii. From ii, I think they didn't find the crucial factor, or didn't find a good way, to solve this problem.
          iv. On the dataset used in paper of Multi-label fashion image classification with minimal human supervision,
              their method is even worser than "Fine-Tuning with clean labels", lmao.
         
    Learning visual n-grams from web data ICCV 2017
    Multi-label fashion image classification with minimal human supervision ICCV 2017
           i. Almost the same models as Learning from noisy large-scale datasets with minimal supervision,
              the difference can be seen from section 4.2 or Figure 5.
           ii. Got less than 1 point improvement on metric AP & MAP, compared to "Fine-Tuning with clean labels", see Table 2.
    
    Iterative Learning with Open-set Noisy Labels CVPR 2018 spotlight
            The key point in this paper is that they uses a algorithm, based on feature distance, to detect outlier/wrong labeled image.
            Their whole algorithm can be seen in figure 3.
            
    AMBIENTGAN: GENERATIVE MODELS FROM LOSSY MEASUREMENTS ICLR 2018 ORAL

    
13. Global Optimality in Neural Network Training

14. Learning from Simulated and Unsupervised Images through Adversarial Training

Githubs:
Openai's platform that you can write your code to play game, then test with this platform. I think it can reduce a lot of your time.
https://github.com/openai/universe

Neural Complete
Use a network to generate another network, the generated network is in Python keras code.
https://github.com/kootenpv/neural_complete


Websites:
1. 如何学习统计学，或我的学习之路——初学者写给初学者
https://cosx.org/2008/11/how-to-learn-statistics-by-jthu/
讲的挺对我的胃口的，感觉这才是真的学习科学的方法。

2. Funny: "Tips on publishing in NIPS, ICML or any top tier conferences for ML"
https://www.reddit.com/r/MachineLearning/comments/3x3urc/tips_on_publishing_in_nips_icml_or_any_top_tier/

3. Changing gazes of people in photos
You can test it online. I tested with my own photo, amazing result
http://163.172.78.19/

4. deep-learning-most-amazing-applications
http://www.yaronhadad.com/deep-learning-most-amazing-applications/

5. Comments on many CVPR2017 papers
http://blog.csdn.net/zhangjunhit/article/category/6801399

6. a blog on MXNET: simple introduction
http://blog.csdn.net/u013713010/article/details/71635814http://blog.csdn.net/u013713010/article/details/71635814

7. comments on CVPR 2017
https://medium.com/@Synced/cvpr-2017-the-fusion-of-deep-learning-and-computer-vision-whats-next-f4d8e9efe2c

8. 图像拼接近年发展，介绍了各个主要方法的核心内容，写的很好
https://www.zhihu.com/question/34535199/answer/135169187

9. Machine Learning Top 10 Open Source Projects (v.Feb 2018)
https://medium.mybridge.co/machine-learning-top-10-open-source-projects-v-feb-2018-d1d39062bd20

10. CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM
Very clear, not hard to understand for new beginners, nice.
https://www.youtube.com/watch?v=iX5V1WpxxkY

11. Understanding LSTM Networks
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
There is no detail equations, for the equations in the article, see
https://www.cnblogs.com/zhangchaoyang/articles/6684906.html

12. CVPR2017 Image Caption有关论文总结
https://zhuanlan.zhihu.com/p/30893160
My: 第三篇Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition里面的黑体"ours"不是最好的"ours"，而是“with a removed”的一个测试，
证明他们的trick有效的。第三篇效果比第一篇效果要好的。可以对比第一篇的table 4和第三篇的table 2
My: 除了这四篇，CVPR2017还有如下image cpation文章:
Deep Reinforcement Learning-Based Image Captioning With Embedding Reward
Captioning Images With Diverse Objects
Self-Critical Sequence Training for Image Captioning

13. The Unreasonable Effectiveness of Recurrent Neural Networks
http://karpathy.github.io/2015/05/21/rnn-effectiveness/

14. A significant drawback of image caption
https://zhuanlan.zhihu.com/p/34188400

15. Very detailed explanation on Hough transformation
https://blog.csdn.net/sunshine_in_moon/article/details/45273909
clear, short, with python code
https://alyssaq.github.io/2014/understanding-hough-transform/
